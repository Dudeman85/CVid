https://learnopengl.com/Getting-started/Coordinate-Systems
Another very important feature for our renderer is being able to move around objects. Right now, we are rendering them all in model space, which means they are relative to the object’s local origin. We want to be able to move these objects around the world without having to redefine the model itself. To do this we apply a transformation to each vertex before passing them to the rasterizer. We also need to set a convention for the x, y, and z axes of our world space. A good convention is the one used by graphics API’s such as OpenGL, where +Y is up [logl].
There are three main transforms we want to do: translation, rotation, and scaling. The proper method of applying these is with a transformation matrix, therefore it is important to have at least a basic understanding of matrix multiplication before trying to understand transformations. 3-dimensional transformation matrices are represented in homogenous coordinates (4x4 matrices), but all of our vertices are in cartesian coordinates (3x1 matrices, or vector 3s). Therefore we need to first understand the basic idea of homogenous coordinates and how they are useful for us. [1.]
For us the useful difference is the distinction between points and vectors. Take A = (1, 2, 3), for example. There is no way to know if A is a point or a vector, but if we add a fourth value  w, we can now represent a vector when w = 0 and a point when w = 1. The cases where w is some other number also represent point, the important part is the ratio between xyz and w. So to convert from cartesian to homogenous coordinates, we can simply add the proper value of w, so A = (1, 2, 3, 0) is a vector, and A = (1, 2, 3, 1) is a point. Converting back from homogenous coordinates to cartesian coordinates is also simple; we divide xyz by w. [1.]
Now to finally transform our objects we need to construct the translation, rotation, and scale matrices, multiply them together for the transformation matrix, and finally multiply each vertice by this matrix.
The translation matrix:
{TODO add matrix somehow}
The scale matrix:

{TODO add matrix somehow}

The rotation matrix:

X:
Y:
Z:

{TODO add matrix somehow}

[byu.]

Now that we have these matrices, we can multiply them together to get our transformation matrix, which we will call the model matrix to avoid confusion with future transformation matrices. The order of the multiplication also matters because translating before rotating will produce different results than rotating before translating. [byu.] Mmodel {TODO subscript} = Mscale * Mrotation * Mtranslation
{TODO: add pseudocode of creating the model matrix}
http://www.et.byu.edu/~ered/ME537/Notes/ch1-537.pdf
2.4.3 Camera
We can now move around objects, next we need a camera that we can move around the scene. The actual implementation of the camera might, however, be counterintuitive at first. Instead of moving the camera, we actually keep the camera still, pointing at -Z and move the entire world around it. Since rotating the camera by R produces identical results to rotating everything in the world by -R, there is no difference in the end result. The same goes for translation. [1.]
{TODO: add picture}
This is much better than the alternative since it greatly simplifies the projection of 3D vertices to 2D points. It is also easy to actually implement. We can use the same matrices as in the last section, just apply them in the reverse order and invert all the transforms. Here we will also only need rotation and translation since a camera's scale works slightly differently and will be implemented in the next section. Therefore our camera transformation matrix, which we will call the view matrix, is Mview = Mtranslation^-1 * Mrotation^-1 [1.]
{TODO add pseudocode of view matrix}
2.4.4 Perspective Projection
https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html
The last  thing we need to do to get our objects rendering as they would in real life is apply a perspective projection to them. The idea with this is to convert 3D points into 2D points on the viewport and render them as a real camera would see them, with farther away objects appearing smaller. We will also want to normalize these points into the range (-1, 1), which is called normalized device coordinates, or NDC. Our vertices will then be in clip space. [logl]
Perspective projection of a point can be calculated using basic trigonometry. Consider the below diagram where P is the point we want to project, P' is the projected point, n is the projection plane, also known as the near clip plane, and the camera is at the origin facing toward -Z. [sp]
{TODO Add picture}
The points ABP and ACP' form two similar triangles, whose properties we can use to calculate p'. By the properties of similar triangles AC/AB = CP'/BP, substituting our known values and solving for BP we get BP = P'y = n * Py / -Pz. Also note that since the camera is facing towards -Z Pz is inverted to preserve the sign of the y coordinate. The same logic works for P'x = n * Px / -Pz. [sp]
Now we have the point P projected to the near clip plane, but we still need to map it to NDC. APIs like OpenGL calculate this by defining the left (l), right (r), top (t), and bottom (b) edges of the camera and mapping the point inside those bounds, we will do the same. We also need to map the z coordinate to between (-1, 1) or (0, 1), which we do with the help of the near (n) and far (f) clip planes. The OpenGL projection matrix maps z to (-1, 1), but (0, 1) is a more standard range and easier for us to work with, so we will slightly modify the matrix to achieve this result. [sp]
{TODO maybe explain derivation}
{TODO Add opengl projection matrix}
Now that we have the projection matrix, we still need to calculate the values it needs. The near and far planes are easy, as they are given by the user. The other values are slightly more difficult, since we will want to calculate them based on the camera's field of view, or fov, and aspect ratio. The fov can be defined as either the vertical or horizontal view angle. Here we will define it as the vertical angle, since that is the convention used by OpenGL, and it makes more sense with the standard way of defining aspect ratio as width/height. Calculating these values is trivial with basic trigonometry.
{TODO add picture}
From the above image you can derive the following:
top = tan(fov / 2) * near
bottom = -top
And for the width and height,  all we have to do is factor in the aspect ratio, which is also given by the user.
right = top * aspectRatio
left = -right
Now we can construct the final projection matrix and apply it to our vertices. For the final step before sending our triangle to the rasterizer, we need to convert it's homogenous coordinates back into cartesian coordinates by diving xyz by w.
{TODO Add pseudocode}